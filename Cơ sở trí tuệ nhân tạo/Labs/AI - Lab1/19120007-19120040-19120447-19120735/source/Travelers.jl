using JuMP
using Ipopt

using Random
using Distributions
using LinearAlgebra
using Plots


struct SimpleGame
    Î³  # discount factor
    â„  # agents
    ğ’œ  # joint action space
    R  # joint reward function
end

struct Travelers 
end

struct SimpleGamePolicy
    p # dictionary mapping actions to probabilities
    function SimpleGamePolicy(p::Base.Generator)
        return SimpleGamePolicy(Dict(p))
    end
    function SimpleGamePolicy(p::Dict)
        vs = collect(values(p))
        vs ./= sum(vs)
        return new(Dict(k => v for (k,v) in zip(keys(p), vs)))
    end
    SimpleGamePolicy(ai) = new(Dict(ai => 1.0))
end

(Ï€i::SimpleGamePolicy)(ai) = get(Ï€i.p, ai, 0.0)

function (Ï€i::SimpleGamePolicy)()
    D = SetCategorical(collect(keys(Ï€i.p)), collect(values(Ï€i.p)))
    return rand(D)
end

joint(X) = vec(collect(Iterators.product(X...)))
joint(Ï€, Ï€i, i) = [i == j ? Ï€i : Ï€j for (j, Ï€j) in enumerate(Ï€)]

function utility(ğ’«::SimpleGame, Ï€, i)
    ğ’œ, R = ğ’«.ğ’œ, ğ’«.R
    p(a) = prod(Ï€j(aj) for (Ï€j, aj) in zip(Ï€, a))
    return sum(R(a)[i]*p(a) for a in joint(ğ’œ))
end

##########################################################################
#Travelers

# agents
n_agents(simpleGame::Travelers) = 2

# joint action space
ordered_actions(simpleGame::Travelers, i::Int) = 2:100
ordered_joint_actions(simpleGame::Travelers) = vec(collect(Iterators.product([ordered_actions(simpleGame, i) for i in 1:n_agents(simpleGame)]...)))
n_joint_actions(simpleGame::Travelers) = length(ordered_joint_actions(simpleGame))
n_actions(simpleGame::Travelers, i::Int) = length(ordered_actions(simpleGame, i))

# joint reward funtion
function reward(simpleGame::Travelers, i::Int, a)
    if i == 1
        noti = 2
    else
        noti = 1
    end
    if a[i] == a[noti]
        r = a[i]
    elseif a[i] < a[noti]
        r = a[i] + 2
    else
        r = a[noti] - 1
    end
    return r
end

function joint_reward(simpleGame::Travelers, a)
    return [reward(simpleGame, i, a) for i in 1:n_agents(simpleGame)]
end

function SimpleGame(simpleGame::Travelers)
    return SimpleGame(
        0.9,
        vec(collect(1:n_agents(simpleGame))),
        [ordered_actions(simpleGame, i) for i in 1:n_agents(simpleGame)],
        (a) -> joint_reward(simpleGame, a)
    )
end



###############################################################################################
# IteratedBestResponse
function best_response(ğ’«::SimpleGame, Ï€, i)
    U(ai) = utility(ğ’«, joint(Ï€, SimpleGamePolicy(ai), i), i)
    ai = argmax(U, ğ’«.ğ’œ[i])
    return SimpleGamePolicy(ai)
end

struct IteratedBestResponse
    k_max # number of iterations
    Ï€ # initial policy
end

function IteratedBestResponse(ğ’«::SimpleGame, k_max)
    Ï€ = [SimpleGamePolicy(ai => 1.0 for ai in ğ’œi) for ğ’œi in ğ’«.ğ’œ]
    return IteratedBestResponse(k_max, Ï€)
end

function solve(M::IteratedBestResponse, ğ’«)
    Ï€ = M.Ï€
    for k in 1:M.k_max
        # update the strategy of each agent
        Ï€ = [best_response(ğ’«, Ï€, i) for i in ğ’«.â„]
    end
    return Ï€
end

#############################################################################################
# Hierarchical Softmax
function softmax_response(ğ’«::SimpleGame, Ï€, i, Î»)
    ğ’œi = ğ’«.ğ’œ[i]
    U(ai) = utility(ğ’«, joint(Ï€, SimpleGamePolicy(ai), i), i)
    return SimpleGamePolicy(ai => exp(Î»*U(ai)) for ai in ğ’œi)
    end

struct HierarchicalSoftmax
    Î» # precision parameter
    k # level
    Ï€ # initial policy
end

function HierarchicalSoftmax(ğ’«::SimpleGame, Î», k)
    Ï€ = [SimpleGamePolicy(ai => 1.0 for ai in ğ’œi) for ğ’œi in ğ’«.ğ’œ]
    return HierarchicalSoftmax(Î», k, Ï€)
end
    
function solve(M::HierarchicalSoftmax, ğ’«)
    Ï€ = M.Ï€
    for k in 1:M.k
        Ï€ = [softmax_response(ğ’«, Ï€, i, M.Î») for i in ğ’«.â„]
    end
    return Ï€
end

ğ’« = SimpleGame(Travelers())
for i in 1:150
    print(string("k = "), i, ": ")
    println(solve(IteratedBestResponse(ğ’«, i), ğ’«))
end


##############################################################################################
function visualization(Î», k)
    ğ’« = SimpleGame(Travelers())
    M = HierarchicalSoftmax(ğ’«, Î», k)
    dict = solve(M, ğ’«)[1].p
    a = []
    b = []
    for i = 2:100
        push!(a, i)
        push!(b, dict[i])
    end
    im = plot(bar(x=a, y=b), Layout(title = string("k=",k, ", lambda=", Î»)))
    filename = string("k=",k, "_lambda=", Î»,".png")
    filename = joinpath(@__DIR__, filename)
    savefig(im, filename)
end

for k = 0:4
    for Î» = [0.1, 0.3, 0.5]    
       visualization(Î», k)
    end
end


